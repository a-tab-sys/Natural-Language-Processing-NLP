{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/a-tab-sys/Natural-Language-Processing-NLP/blob/master/04%20Word_embedding_Techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHNf7J680XF-"
   },
   "source": [
    "### Word Embedding Techniques using Embedding Layer in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEsK0_yl0XGB"
   },
   "source": [
    "### Libraries USed Tensorflow> 2.0  and keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pslw1Ya90XGC",
    "outputId": "de66f2dd-43d6-4477-9fb8-4ed421b4cbe4"
   },
   "outputs": [],
   "source": [
    "# this is no longer applicable:\n",
    "# pip uninstall tensorflow-gpu\n",
    "# error is related to compatibility issues with the tensorflow-gpu package\n",
    "# the main cause is that tensorflow-gpu is deprecated starting from TensorFlow 2.1 and is now merged into the main tensorflow package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hasaan\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "# verify GPU support after installation, you can check if TensorFlow is recognizing your GPU\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "k4nKifUl0XGC"
   },
   "outputs": [],
   "source": [
    "# library helps you perform one hot encoding\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Fu9PuYeu0XGD"
   },
   "outputs": [],
   "source": [
    "### sentences\n",
    "# our sentance size is not consistant, some sentances have 4 words, some have 5\n",
    "# when we are training a neural network, your sentance, input size have to be fixed\n",
    "# to fix this issue we will use post and pre padding\n",
    "sent=[  'the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "    'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x5d1D3_20XGD",
    "outputId": "3e3abb89-c992-4620-b332-696d5728fa3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "tjnXIn3B0XGE"
   },
   "outputs": [],
   "source": [
    "# have to specify vocabulary size - arbitrary value, could be set to anything\n",
    "# larger vocablary size gives you larger feature representation\n",
    "voc_size=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vQOdeKk0XGE"
   },
   "source": [
    "#### One Hot Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gojfZpAW0XGE",
    "outputId": "edd9dce0-84d3-4fe5-a371-121ccdb726bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[59, 91, 161, 276], [59, 91, 161, 478], [59, 195, 161, 38], [431, 419, 151, 203, 366], [431, 419, 151, 203, 147], [332, 59, 331, 161, 277], [280, 215, 294, 203]]\n"
     ]
    }
   ],
   "source": [
    "# captures indexes\n",
    "# each vector list is the OHE version of the sentance.\n",
    "# for instance in \"the glass of milk\", \"the\" is in the index position 180, \"glass\" is in the index position 405\n",
    "onehot_repr=[one_hot(words,voc_size)for words in sent]\n",
    "print(onehot_repr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYG267x40XGF"
   },
   "source": [
    "#### Word Embedding Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "wpqPm0tb0XGF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "Rov3GTM00XGG"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fQLPw6p0XGG",
    "outputId": "ce86ec66-da15-4988-e300-ff72eeb229ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0  59  91 161 276]\n",
      " [  0   0   0   0  59  91 161 478]\n",
      " [  0   0   0   0  59 195 161  38]\n",
      " [  0   0   0 431 419 151 203 366]\n",
      " [  0   0   0 431 419 151 203 147]\n",
      " [  0   0   0 332  59 331 161 277]\n",
      " [  0   0   0   0 280 215 294 203]]\n"
     ]
    }
   ],
   "source": [
    "### pre padding\n",
    "# from our dataset, our largest sentance is actually 5 words but to understand padding, lets set this to 8\n",
    "# so the pad-sequesnce will make sure that wherever the OHE representation of our vector is 4 or 5, it is going to make it 8\n",
    "# it is gonna do this using padding- here we are using pre secifically. if we use post, 0's will be added to the end\n",
    "sent_length=8\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "yjQqBYac0XGG"
   },
   "outputs": [],
   "source": [
    "### feature dimensions\n",
    "# now for example with this sentance: [  0   0   0   0  59  91 161 276]\n",
    "# so for each and every value in the above sentance, we will provide that in the form of feature representation\n",
    "# we are setting our feature representaiton size as 10\n",
    "dim=10\n",
    "# so esscentially the example the first 0 in our sentance above would be represented by 10 values. THIS IS ESSCENTIALLY WOD2VEC\n",
    "# [ 0.4\n",
    "    0.5\n",
    "    045\n",
    "    1.2\n",
    "    2.4\n",
    "    0.76\n",
    "    0.78\n",
    "    1.3\n",
    "    3.2\n",
    "    0   ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozC-TXrt0XGG"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,10,input_length=sent_length))\n",
    "# the embedding layer below works similar to word2vec, it will train our neural network\n",
    "# arguments include <voc size, how many features per vector (could be dim varibale defined above), specify input length which is our sentance length, which is 8>\n",
    "model.compile('adam','mse')\n",
    "# compiling with adam and qaamean square error, and taking the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMNvq-Ji0XGH",
    "outputId": "8bde65d1-06cf-4f8b-9767-28077ff2aeca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FC4Ess_FEcb3",
    "outputId": "e35d2a7c-ff4b-4332-c2c2-dc32249595a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,  59,  91, 161, 276])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'the glass of milk',\n",
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRqEvMBYEZUS",
    "outputId": "021bd422-238e-4a3f-daa2-09323ef3153a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00298679,  0.02932216,  0.02459887, -0.01831581, -0.03383742,\n",
       "         0.02392096, -0.04072629,  0.00456358, -0.04682035, -0.0052909 ],\n",
       "       [ 0.00298679,  0.02932216,  0.02459887, -0.01831581, -0.03383742,\n",
       "         0.02392096, -0.04072629,  0.00456358, -0.04682035, -0.0052909 ],\n",
       "       [ 0.00298679,  0.02932216,  0.02459887, -0.01831581, -0.03383742,\n",
       "         0.02392096, -0.04072629,  0.00456358, -0.04682035, -0.0052909 ],\n",
       "       [ 0.00298679,  0.02932216,  0.02459887, -0.01831581, -0.03383742,\n",
       "         0.02392096, -0.04072629,  0.00456358, -0.04682035, -0.0052909 ],\n",
       "       [-0.00902073, -0.04047633, -0.04965064, -0.01325365, -0.03963579,\n",
       "        -0.0161491 ,  0.00109575, -0.02132442,  0.03011035,  0.04604227],\n",
       "       [-0.01142861, -0.02867019,  0.01654385,  0.04083909,  0.04539467,\n",
       "         0.0361747 ,  0.04886154, -0.00536014,  0.034936  , -0.04806005],\n",
       "       [ 0.02368667,  0.03151972, -0.02726269, -0.04854659, -0.03845816,\n",
       "         0.01311852,  0.00633377, -0.04570239,  0.00713151,  0.03938884],\n",
       "       [ 0.01704365,  0.01441607, -0.01641969,  0.00734406,  0.03015777,\n",
       "         0.0043456 ,  0.02641397,  0.01163996,  0.04041846, -0.01540982]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzKP69gx0XGH",
    "outputId": "4558c7ab-6692-4aa3-b958-e7bbfeb0474d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "[[[ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03059326 -0.04286614  0.00899569  0.00743791 -0.000781\n",
      "    0.04186494  0.03977301  0.00326709  0.00619651 -0.01993654]\n",
      "  [ 0.02512412 -0.0087087   0.03144198  0.00704668 -0.00177735\n",
      "   -0.03415867 -0.00100178  0.01562483  0.03178963  0.02784893]\n",
      "  [-0.00653008  0.02340979 -0.01967902 -0.00494973 -0.02693756\n",
      "   -0.03746525  0.01460877 -0.00449115 -0.00130982 -0.0039017 ]\n",
      "  [-0.03150218  0.01950303 -0.01415605 -0.00183152  0.01207731\n",
      "    0.02444079  0.0140041   0.0070256   0.04950741 -0.03602346]]\n",
      "\n",
      " [[ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03059326 -0.04286614  0.00899569  0.00743791 -0.000781\n",
      "    0.04186494  0.03977301  0.00326709  0.00619651 -0.01993654]\n",
      "  [ 0.02512412 -0.0087087   0.03144198  0.00704668 -0.00177735\n",
      "   -0.03415867 -0.00100178  0.01562483  0.03178963  0.02784893]\n",
      "  [-0.00653008  0.02340979 -0.01967902 -0.00494973 -0.02693756\n",
      "   -0.03746525  0.01460877 -0.00449115 -0.00130982 -0.0039017 ]\n",
      "  [-0.0434371   0.01733501 -0.0254814   0.03025435 -0.0460149\n",
      "    0.00874413  0.04856688  0.03454936 -0.02982813 -0.00472248]]\n",
      "\n",
      " [[ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03059326 -0.04286614  0.00899569  0.00743791 -0.000781\n",
      "    0.04186494  0.03977301  0.00326709  0.00619651 -0.01993654]\n",
      "  [-0.0165449  -0.0245487  -0.04049651 -0.03379797  0.03827978\n",
      "   -0.01891239  0.03935272  0.03601534  0.04047254  0.02626738]\n",
      "  [-0.00653008  0.02340979 -0.01967902 -0.00494973 -0.02693756\n",
      "   -0.03746525  0.01460877 -0.00449115 -0.00130982 -0.0039017 ]\n",
      "  [-0.01796211  0.03012553  0.02499587 -0.03019696 -0.02619814\n",
      "   -0.04370998  0.02499839  0.0259905  -0.02895923 -0.03277919]]\n",
      "\n",
      " [[ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.0455125  -0.01906607 -0.01224751 -0.00509113 -0.02193579\n",
      "   -0.01053187 -0.02626517 -0.00871019  0.04797108  0.01489766]\n",
      "  [ 0.01335182 -0.03833141  0.01346098  0.02035983 -0.03607824\n",
      "   -0.03206537  0.02643689  0.03777478 -0.00899317  0.01333355]\n",
      "  [-0.00676087  0.03904044  0.00479779 -0.02978393  0.02397071\n",
      "    0.03766178 -0.0092328  -0.03824631 -0.03726087  0.04569164]\n",
      "  [-0.04575538  0.04188532  0.01740856 -0.00267079 -0.00815887\n",
      "   -0.04747143 -0.02846756 -0.00109354 -0.00825974  0.03024724]\n",
      "  [ 0.01152636  0.04342527  0.0201059   0.0143644  -0.0240415\n",
      "    0.01083563 -0.03891394  0.03182233 -0.04408182 -0.00053762]]\n",
      "\n",
      " [[ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.0455125  -0.01906607 -0.01224751 -0.00509113 -0.02193579\n",
      "   -0.01053187 -0.02626517 -0.00871019  0.04797108  0.01489766]\n",
      "  [ 0.01335182 -0.03833141  0.01346098  0.02035983 -0.03607824\n",
      "   -0.03206537  0.02643689  0.03777478 -0.00899317  0.01333355]\n",
      "  [-0.00676087  0.03904044  0.00479779 -0.02978393  0.02397071\n",
      "    0.03766178 -0.0092328  -0.03824631 -0.03726087  0.04569164]\n",
      "  [-0.04575538  0.04188532  0.01740856 -0.00267079 -0.00815887\n",
      "   -0.04747143 -0.02846756 -0.00109354 -0.00825974  0.03024724]\n",
      "  [-0.04356548  0.02670497 -0.0180442  -0.00757015  0.00827466\n",
      "    0.01629097  0.00119376 -0.04088793  0.03524628  0.0412981 ]]\n",
      "\n",
      " [[ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [-0.04503573 -0.01525755  0.0247951   0.0397242  -0.01098786\n",
      "   -0.01889135  0.01474792  0.01420038  0.01264313 -0.02099638]\n",
      "  [ 0.03059326 -0.04286614  0.00899569  0.00743791 -0.000781\n",
      "    0.04186494  0.03977301  0.00326709  0.00619651 -0.01993654]\n",
      "  [-0.00189289 -0.01293756  0.01065254  0.00630366  0.02548606\n",
      "   -0.02246332 -0.03166081  0.0488782   0.04733732 -0.00055351]\n",
      "  [-0.00653008  0.02340979 -0.01967902 -0.00494973 -0.02693756\n",
      "   -0.03746525  0.01460877 -0.00449115 -0.00130982 -0.0039017 ]\n",
      "  [ 0.01523279  0.03147752 -0.00877231 -0.04363536  0.02689752\n",
      "    0.0303895   0.03939242 -0.01938576  0.03533088  0.04882917]]\n",
      "\n",
      " [[ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.03938437 -0.02009605 -0.03878935 -0.04955565  0.00419912\n",
      "   -0.01431773  0.02523251  0.01653036  0.04291571 -0.00864979]\n",
      "  [ 0.02216006 -0.03527117 -0.04675846 -0.01894816  0.03763377\n",
      "    0.03965045  0.04765204 -0.00806187 -0.01859087 -0.02574421]\n",
      "  [ 0.04836557 -0.01613583  0.00869457  0.02868301  0.0297311\n",
      "   -0.04792688  0.02694935 -0.02964565  0.03412347 -0.03255747]\n",
      "  [ 0.03478764 -0.0400234   0.01112056 -0.00944598  0.00491976\n",
      "    0.02883413 -0.00612055 -0.00938722  0.01297954 -0.00811065]\n",
      "  [-0.04575538  0.04188532  0.01740856 -0.00267079 -0.00815887\n",
      "   -0.04747143 -0.02846756 -0.00109354 -0.00825974  0.03024724]]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(embedded_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JuUxfk7d0XGH",
    "outputId": "c28e6fc6-3db2-4975-9dd3-950b7da8c67e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0, 6654,  998, 8966, 1609])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6JJ_zD0u0XGH",
    "outputId": "8b2b65cb-457b-46f4-dd60-c5fe8ab0566f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00425554 -0.00159295 -0.04714153  0.04425247 -0.00973954 -0.04325813\n",
      "   0.04007108 -0.0143286  -0.03659749 -0.02379028]\n",
      " [-0.00425554 -0.00159295 -0.04714153  0.04425247 -0.00973954 -0.04325813\n",
      "   0.04007108 -0.0143286  -0.03659749 -0.02379028]\n",
      " [-0.00425554 -0.00159295 -0.04714153  0.04425247 -0.00973954 -0.04325813\n",
      "   0.04007108 -0.0143286  -0.03659749 -0.02379028]\n",
      " [-0.00425554 -0.00159295 -0.04714153  0.04425247 -0.00973954 -0.04325813\n",
      "   0.04007108 -0.0143286  -0.03659749 -0.02379028]\n",
      " [-0.03786323 -0.02628061  0.02974111 -0.03307171  0.0271405   0.00945134\n",
      "   0.02378127  0.04176904  0.00514941  0.0152082 ]\n",
      " [ 0.04834186  0.04388311 -0.02802253 -0.01475487 -0.01212303  0.03762435\n",
      "  -0.01166249 -0.02141088  0.04654533  0.01537322]\n",
      " [ 0.03276015 -0.00637691  0.03907344 -0.01912468  0.02177186 -0.04630325\n",
      "   0.00800942 -0.03115667 -0.00486455 -0.04843524]\n",
      " [-0.04173617  0.03438064  0.02880521 -0.01896455  0.0323303  -0.00109453\n",
      "  -0.01675171 -0.00941917 -0.03309294 -0.04779492]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(embedded_docs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OMu3iAz0XGH"
   },
   "outputs": [],
   "source": [
    "### Assignment\n",
    "# go to kaggle, get the imdb 50k movie review dataset, and convert to vectors\n",
    "# also take up the sentances below, and convert to vectors\n",
    "\n",
    "sent=[\"The world is a better place\",\n",
    "      \"Marvel series is my favourite movie\",\n",
    "      \"I like DC movies\",\n",
    "      \"the cat is eating the food\",\n",
    "      \"Tom and Jerry is my favourite movie\",\n",
    "      \"Python is my favourite programming language\"\n",
    "      ]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
